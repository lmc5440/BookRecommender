{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Books Reviews dataset loaded:\n",
      "           Id                               Title  Price         User_id  \\\n",
      "0  0671551345  Night World: Daughters Of Darkness    NaN   ADB0JID2XRFYR   \n",
      "1  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
      "2  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
      "3  0671551345  Night World: Daughters Of Darkness    NaN  A1V0SFB3AXM8JK   \n",
      "4  0671551345  Night World: Daughters Of Darkness    NaN             NaN   \n",
      "\n",
      "                                       profileName review/helpfulness  \\\n",
      "0  Harmony-Faith Charisma Izabela Jazmyn McDonague                1/3   \n",
      "1                                              NaN                1/3   \n",
      "2                                              NaN                1/3   \n",
      "3                        K. Davis \"The Rose Bride\"                0/2   \n",
      "4                                              NaN                0/0   \n",
      "\n",
      "   review/score  review/time  \\\n",
      "0           5.0   1076457600   \n",
      "1           5.0   1043971200   \n",
      "2           3.0    960422400   \n",
      "3           1.0   1177718400   \n",
      "4           5.0    889920000   \n",
      "\n",
      "                                      review/summary  \\\n",
      "0                                   BEST BOOK EVER!!   \n",
      "1              one of the best night world books!!!!   \n",
      "2                    three sisters to die for.......   \n",
      "3                     Disappointing to say the least   \n",
      "4  The most charming, captivating work from LJ Sm...   \n",
      "\n",
      "                                         review/text  \n",
      "0  This is 1 of da bst books dat i have EVER read...  \n",
      "1  first of all i thought that this was one of lj...  \n",
      "2  Once started I couldn't put it down, literally...  \n",
      "3  This book is probably, in my opinion, one of (...  \n",
      "4  The plot and characters are incredible. Everyo...  \n",
      "\n",
      "GoodReads Books dataset loaded:\n",
      "                     title                         titleComplete  \\\n",
      "0        Project Hail Mary                     Project Hail Mary   \n",
      "1  The Talented Mr. Ripley  The Talented Mr. Ripley (Ripley, #1)   \n",
      "2           More Than This                        More Than This   \n",
      "3       After Forever Ends                    After Forever Ends   \n",
      "4     A Bird Without Wings                  A Bird Without Wings   \n",
      "\n",
      "                                         description  \\\n",
      "0  Ryland Grace is the sole survivor on a despera...   \n",
      "1  Since his debut in 1955, Tom Ripley has evolve...   \n",
      "2  A boy drowns, desperate and alone in his final...   \n",
      "3  Orphaned by her mother and brushed off by her ...   \n",
      "4  After an impoverished and indigent childhood, ...   \n",
      "\n",
      "                                              genres        isbn  \\\n",
      "0  ['Science Fiction Fantasy', 'Audiobook', 'Fant...  0593135202   \n",
      "1  ['Novels', 'Noir', 'Classics', 'Italy', 'Suspe...  0393332144   \n",
      "2  ['Queer', 'Fantasy', 'Contemporary', 'LGBT', '...  1406350486   \n",
      "3  ['Chick Lit', 'Fantasy', 'Coming Of Age', 'Con...         NaN   \n",
      "4  ['Contemporary', 'Contemporary Romance', 'Roma...         NaN   \n",
      "\n",
      "               publisher                  author  \\\n",
      "0       Ballantine Books           ['Andy Weir']   \n",
      "1  W. W. Norton  Company  ['Patricia Highsmith']   \n",
      "2       Walker Books Ltd        ['Patrick Ness']   \n",
      "3       Gingersnap Press      ['Melodie Ramone']   \n",
      "4             Smashwords      ['Roberta Pearce']   \n",
      "\n",
      "                                          characters  \\\n",
      "0                          ['Ryland Grace', 'Rocky']   \n",
      "1  ['Freddie Miles', 'Tom Ripley', 'Dickie Greenl...   \n",
      "2                                   ['Seth Wearing']   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                                              places  \\\n",
      "0                 ['Tau Ceti System', 'Outer Space']   \n",
      "1  ['Italy', 'New York City, New York', 'Italian ...   \n",
      "2                                                NaN   \n",
      "3                                                NaN   \n",
      "4                                                NaN   \n",
      "\n",
      "                       ratingHistogram  ratingsCount  reviewsCount  numPages  \\\n",
      "0  [1917, 5775, 29742, 116572, 266669]      420675.0       53538.0     476.0   \n",
      "1    [1483, 3902, 17161, 34467, 24270]       81283.0        5146.0     288.0   \n",
      "2    [1441, 3672, 12295, 23873, 21208]       62489.0        8194.0     480.0   \n",
      "3             [81, 119, 205, 365, 750]        1520.0         241.0     564.0   \n",
      "4                   [7, 6, 26, 49, 91]         179.0          31.0       NaN   \n",
      "\n",
      "  language  \n",
      "0  English  \n",
      "1  English  \n",
      "2  English  \n",
      "3  English  \n",
      "4  English  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Amazon Books Reviews dataset\n",
    "amazon_reviews_path = 'data/book_reviews.csv'  # Adjust file path as needed\n",
    "amazon_df = pd.read_csv(amazon_reviews_path)\n",
    "print(\"Amazon Books Reviews dataset loaded:\")\n",
    "print(amazon_df.head())\n",
    "\n",
    "# Load the GoodReads Books dataset (with Description and Genre)\n",
    "goodreads_path = 'data/goodreads_dataset.csv'  # Adjust file path as needed\n",
    "goodreads_df = pd.read_csv(goodreads_path)\n",
    "print(\"\\nGoodReads Books dataset loaded:\")\n",
    "print(goodreads_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preliminary Data Exploration\n",
    "\n",
    "Next, we check the structure and basic statistics for both datasets. This helps us identify any issues like missing values or duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Reviews DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17158 entries, 0 to 17157\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Id                  17158 non-null  object \n",
      " 1   Title               17158 non-null  object \n",
      " 2   Price               10897 non-null  float64\n",
      " 3   User_id             14573 non-null  object \n",
      " 4   profileName         14572 non-null  object \n",
      " 5   review/helpfulness  17158 non-null  object \n",
      " 6   review/score        17158 non-null  float64\n",
      " 7   review/time         17158 non-null  int64  \n",
      " 8   review/summary      17155 non-null  object \n",
      " 9   review/text         17158 non-null  object \n",
      "dtypes: float64(2), int64(1), object(7)\n",
      "memory usage: 1.3+ MB\n",
      "\n",
      "GoodReads DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14712 entries, 0 to 14711\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   title            14712 non-null  object \n",
      " 1   titleComplete    14712 non-null  object \n",
      " 2   description      14712 non-null  object \n",
      " 3   genres           14712 non-null  object \n",
      " 4   isbn             11738 non-null  object \n",
      " 5   publisher        14042 non-null  object \n",
      " 6   author           14710 non-null  object \n",
      " 7   characters       7177 non-null   object \n",
      " 8   places           5971 non-null   object \n",
      " 9   ratingHistogram  14709 non-null  object \n",
      " 10  ratingsCount     14709 non-null  float64\n",
      " 11  reviewsCount     14692 non-null  float64\n",
      " 12  numPages         14467 non-null  float64\n",
      " 13  language         14358 non-null  object \n",
      "dtypes: float64(3), object(11)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "Missing values in Amazon Reviews:\n",
      "Id                       0\n",
      "Title                    0\n",
      "Price                 6261\n",
      "User_id               2585\n",
      "profileName           2586\n",
      "review/helpfulness       0\n",
      "review/score             0\n",
      "review/time              0\n",
      "review/summary           3\n",
      "review/text              0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in GoodReads dataset:\n",
      "title                 0\n",
      "titleComplete         0\n",
      "description           0\n",
      "genres                0\n",
      "isbn               2974\n",
      "publisher           670\n",
      "author                2\n",
      "characters         7535\n",
      "places             8741\n",
      "ratingHistogram       3\n",
      "ratingsCount          3\n",
      "reviewsCount         20\n",
      "numPages            245\n",
      "language            354\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display basic info about each dataset\n",
    "print(\"Amazon Reviews DataFrame Info:\")\n",
    "amazon_df.info()\n",
    "print(\"\\nGoodReads DataFrame Info:\")\n",
    "goodreads_df.info()\n",
    "\n",
    "# Check for missing values in each dataset\n",
    "print(\"\\nMissing values in Amazon Reviews:\")\n",
    "print(amazon_df.isnull().sum())\n",
    "print(\"\\nMissing values in GoodReads dataset:\")\n",
    "print(goodreads_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning\n",
    "\n",
    "We clean the data by removing duplicates and handling missing values. For now, we drop rows with missing data; you can later choose to impute values if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Amazon Reviews shape: (9296, 10)\n",
      "Cleaned GoodReads shape: (3831, 14)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate entries from both datasets\n",
    "amazon_df_clean = amazon_df.drop_duplicates()\n",
    "goodreads_df_clean = goodreads_df.drop_duplicates()\n",
    "\n",
    "# Drop rows with missing values\n",
    "amazon_df_clean = amazon_df_clean.dropna()\n",
    "goodreads_df_clean = goodreads_df_clean.dropna()\n",
    "\n",
    "# Verify cleaning steps\n",
    "print(\"Cleaned Amazon Reviews shape:\", amazon_df_clean.shape)\n",
    "print(\"Cleaned GoodReads shape:\", goodreads_df_clean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging the Datasets\n",
    "\n",
    " we merge the Amazon Reviews into it by matching the GoodReads isbn with the Amazon Id. We include the review/text column from the Amazon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in Amazon Reviews: Index(['Id', 'Title', 'Price', 'User_id', 'profileName', 'review/helpfulness',\n",
      "       'review/score', 'review/time', 'review/summary', 'review/text'],\n",
      "      dtype='object')\n",
      "Columns in GoodReads dataset: Index(['title', 'titleComplete', 'description', 'genres', 'isbn', 'publisher',\n",
      "       'author', 'characters', 'places', 'ratingHistogram', 'ratingsCount',\n",
      "       'reviewsCount', 'numPages', 'language'],\n",
      "      dtype='object')\n",
      "Merged DataFrame preview:\n",
      "                       title  \\\n",
      "0          Project Hail Mary   \n",
      "1    The Talented Mr. Ripley   \n",
      "2   Tell the Wolves I'm Home   \n",
      "3      P.S. I Still Love You   \n",
      "4  The House on Mango Street   \n",
      "\n",
      "                                       titleComplete  \\\n",
      "0                                  Project Hail Mary   \n",
      "1               The Talented Mr. Ripley (Ripley, #1)   \n",
      "2                           Tell the Wolves I'm Home   \n",
      "3  P.S. I Still Love You (To All the Boys I've Lo...   \n",
      "4                          The House on Mango Street   \n",
      "\n",
      "                                         description  \\\n",
      "0  Ryland Grace is the sole survivor on a despera...   \n",
      "1  Since his debut in 1955, Tom Ripley has evolve...   \n",
      "2  In this striking literary debut, Carol Rifka B...   \n",
      "3  Lara Jean didn’t expect to really fall for Pet...   \n",
      "4  Acclaimed by critics, beloved by readers of al...   \n",
      "\n",
      "                                              genres        isbn  \\\n",
      "0  ['Science Fiction Fantasy', 'Audiobook', 'Fant...  0593135202   \n",
      "1  ['Novels', 'Noir', 'Classics', 'Italy', 'Suspe...  0393332144   \n",
      "2  ['Coming Of Age', 'Contemporary', 'Realistic F...  0679644199   \n",
      "3  ['Audiobook', 'Chick Lit', 'Contemporary', 'Yo...  144242673X   \n",
      "4  ['Coming Of Age', 'Contemporary', 'Poetry', 'R...  0679734775   \n",
      "\n",
      "                                  publisher                  author  \\\n",
      "0                          Ballantine Books           ['Andy Weir']   \n",
      "1                     W. W. Norton  Company  ['Patricia Highsmith']   \n",
      "2                              Random House   ['Carol Rifka Brunt']   \n",
      "3  Simon & Schuster Books for Young Readers           ['Jenny Han']   \n",
      "4                                   Vintage     ['Sandra Cisneros']   \n",
      "\n",
      "                                          characters  \\\n",
      "0                          ['Ryland Grace', 'Rocky']   \n",
      "1  ['Freddie Miles', 'Tom Ripley', 'Dickie Greenl...   \n",
      "2  ['Finn Weiss', 'Danni Elbus', 'Toby Aldshaw', ...   \n",
      "3  ['Lara Jean', 'Kitty', 'Margot', 'Peter Kavins...   \n",
      "4                             ['Nenny', 'Esperanza']   \n",
      "\n",
      "                                              places  \\\n",
      "0                 ['Tau Ceti System', 'Outer Space']   \n",
      "1  ['Italy', 'New York City, New York', 'Italian ...   \n",
      "2  ['New York City, New York', 'Westchester, New ...   \n",
      "3                      ['Charlottesville, Virginia']   \n",
      "4                              ['Chicago, Illinois']   \n",
      "\n",
      "                        ratingHistogram  ratingsCount  reviewsCount  numPages  \\\n",
      "0   [1917, 5775, 29742, 116572, 266669]      420675.0       53538.0     476.0   \n",
      "1     [1483, 3902, 17161, 34467, 24270]       81283.0        5146.0     288.0   \n",
      "2     [2434, 6435, 25132, 54594, 49453]      138048.0       15491.0     360.0   \n",
      "3  [3828, 14220, 69988, 132580, 122455]      343071.0       27039.0     337.0   \n",
      "4    [6128, 15183, 46748, 60133, 42220]      170412.0       14951.0     110.0   \n",
      "\n",
      "  language review/text  \n",
      "0  English         NaN  \n",
      "1  English         NaN  \n",
      "2  English         NaN  \n",
      "3  English         NaN  \n",
      "4  English         NaN  \n",
      "Merged DataFrame shape: (7577, 15)\n"
     ]
    }
   ],
   "source": [
    "# Inspect the common columns to verify merge keys\n",
    "print(\"Columns in Amazon Reviews:\", amazon_df_clean.columns)\n",
    "print(\"Columns in GoodReads dataset:\", goodreads_df_clean.columns)\n",
    "\n",
    "# Merge on GoodReads' 'isbn' and Amazon's 'Id'\n",
    "# We take only the necessary columns from Amazon (Id and review/text)\n",
    "merged_df = pd.merge(goodreads_df_clean,\n",
    "                     amazon_df_clean[['Id', 'review/text']],\n",
    "                     how='left',\n",
    "                     left_on='isbn',\n",
    "                     right_on='Id')\n",
    "\n",
    "\n",
    "merged_df = merged_df.drop(columns=['Id'])\n",
    "\n",
    "print(\"Merged DataFrame preview:\")\n",
    "print(merged_df.head())\n",
    "print(\"Merged DataFrame shape:\", merged_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting the Cleaned and Merged Data\n",
    "\n",
    "After merging, we export the cleaned individual datasets and the merged dataset for later use in our model training and evaluation stages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned datasets and merged data exported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Export the cleaned individual datasets and merged dataset to CSV files\n",
    "amazon_df_clean.to_csv('data/amazon_reviews_clean.csv', index=False)\n",
    "goodreads_df_clean.to_csv('data/goodreads_clean.csv', index=False)\n",
    "merged_df.to_csv('data/merged_books_data.csv', index=False)\n",
    "\n",
    "print(\"Cleaned datasets and merged data exported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction for Content-Based Recommender\n",
    "\n",
    "First, we’ll create a combined text field from the book description and review text. Then, we’ll use scikit-learn’s TF-IDF vectorizer to extract features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged dataset loaded. Sample:\n",
      "                       title  \\\n",
      "0          Project Hail Mary   \n",
      "1    The Talented Mr. Ripley   \n",
      "2   Tell the Wolves I'm Home   \n",
      "3      P.S. I Still Love You   \n",
      "4  The House on Mango Street   \n",
      "\n",
      "                                       titleComplete  \\\n",
      "0                                  Project Hail Mary   \n",
      "1               The Talented Mr. Ripley (Ripley, #1)   \n",
      "2                           Tell the Wolves I'm Home   \n",
      "3  P.S. I Still Love You (To All the Boys I've Lo...   \n",
      "4                          The House on Mango Street   \n",
      "\n",
      "                                         description  \\\n",
      "0  Ryland Grace is the sole survivor on a despera...   \n",
      "1  Since his debut in 1955, Tom Ripley has evolve...   \n",
      "2  In this striking literary debut, Carol Rifka B...   \n",
      "3  Lara Jean didn’t expect to really fall for Pet...   \n",
      "4  Acclaimed by critics, beloved by readers of al...   \n",
      "\n",
      "                                              genres        isbn  \\\n",
      "0  ['Science Fiction Fantasy', 'Audiobook', 'Fant...  0593135202   \n",
      "1  ['Novels', 'Noir', 'Classics', 'Italy', 'Suspe...  0393332144   \n",
      "2  ['Coming Of Age', 'Contemporary', 'Realistic F...  0679644199   \n",
      "3  ['Audiobook', 'Chick Lit', 'Contemporary', 'Yo...  144242673X   \n",
      "4  ['Coming Of Age', 'Contemporary', 'Poetry', 'R...  0679734775   \n",
      "\n",
      "                                  publisher                  author  \\\n",
      "0                          Ballantine Books           ['Andy Weir']   \n",
      "1                     W. W. Norton  Company  ['Patricia Highsmith']   \n",
      "2                              Random House   ['Carol Rifka Brunt']   \n",
      "3  Simon & Schuster Books for Young Readers           ['Jenny Han']   \n",
      "4                                   Vintage     ['Sandra Cisneros']   \n",
      "\n",
      "                                          characters  \\\n",
      "0                          ['Ryland Grace', 'Rocky']   \n",
      "1  ['Freddie Miles', 'Tom Ripley', 'Dickie Greenl...   \n",
      "2  ['Finn Weiss', 'Danni Elbus', 'Toby Aldshaw', ...   \n",
      "3  ['Lara Jean', 'Kitty', 'Margot', 'Peter Kavins...   \n",
      "4                             ['Nenny', 'Esperanza']   \n",
      "\n",
      "                                              places  \\\n",
      "0                 ['Tau Ceti System', 'Outer Space']   \n",
      "1  ['Italy', 'New York City, New York', 'Italian ...   \n",
      "2  ['New York City, New York', 'Westchester, New ...   \n",
      "3                      ['Charlottesville, Virginia']   \n",
      "4                              ['Chicago, Illinois']   \n",
      "\n",
      "                        ratingHistogram  ratingsCount  reviewsCount  numPages  \\\n",
      "0   [1917, 5775, 29742, 116572, 266669]      420675.0       53538.0     476.0   \n",
      "1     [1483, 3902, 17161, 34467, 24270]       81283.0        5146.0     288.0   \n",
      "2     [2434, 6435, 25132, 54594, 49453]      138048.0       15491.0     360.0   \n",
      "3  [3828, 14220, 69988, 132580, 122455]      343071.0       27039.0     337.0   \n",
      "4    [6128, 15183, 46748, 60133, 42220]      170412.0       14951.0     110.0   \n",
      "\n",
      "  language review/text  \n",
      "0  English         NaN  \n",
      "1  English         NaN  \n",
      "2  English         NaN  \n",
      "3  English         NaN  \n",
      "4  English         NaN  \n",
      "\n",
      "Combined text features preview:\n",
      "                       title  \\\n",
      "0          Project Hail Mary   \n",
      "1    The Talented Mr. Ripley   \n",
      "2   Tell the Wolves I'm Home   \n",
      "3      P.S. I Still Love You   \n",
      "4  The House on Mango Street   \n",
      "\n",
      "                                       text_features  \n",
      "0  Ryland Grace is the sole survivor on a despera...  \n",
      "1  Since his debut in 1955, Tom Ripley has evolve...  \n",
      "2  In this striking literary debut, Carol Rifka B...  \n",
      "3  Lara Jean didn’t expect to really fall for Pet...  \n",
      "4  Acclaimed by critics, beloved by readers of al...  \n",
      "\n",
      "TF-IDF matrix shape: (7577, 5000)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load the merged dataset\n",
    "merged_df = pd.read_csv('data/merged_books_data.csv')\n",
    "print(\"Merged dataset loaded. Sample:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Create a new column 'text_features' combining description and review text\n",
    "merged_df['text_features'] = merged_df['description'].fillna('') + \" \" + merged_df['review/text'].fillna('')\n",
    "print(\"\\nCombined text features preview:\")\n",
    "print(merged_df[['title', 'text_features']].head())\n",
    "\n",
    "# Use TF-IDF to convert text data to vectors\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(merged_df['text_features'])\n",
    "\n",
    "print(\"\\nTF-IDF matrix shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Content-Based Recommender\n",
    "\n",
    "Using the TF-IDF vectors, we compute cosine similarity between books. This allows us to define a function that, given a book title, recommends similar books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute cosine similarity between TF-IDF feature vectors\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Create a mapping from book title to index\n",
    "indices = pd.Series(merged_df.index, index=merged_df['title']).drop_duplicates()\n",
    "\n",
    "def recommend_books(title, cosine_sim=cosine_sim, df=merged_df, indices=indices, top_n=5):\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = indices.get(title)\n",
    "    if idx is None:\n",
    "        return \"Book not found in our dataset.\"\n",
    "    \n",
    "    # Get the pairwise similarity scores of all books with that book\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    # Skip the first one since it is the book itself\n",
    "    sim_scores = sim_scores[1: top_n+1]\n",
    "    # Get the indices of the most similar books\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # Return the top n most similar books\n",
    "    return df[['title', 'genre']].iloc[book_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genre Classification Model using Keras\n",
    "\n",
    "We now build a simple feed-forward neural network to classify a book’s genre based on its text features. This serves as a training task and evaluation metric for our feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 6061\n",
      "Test samples: 1516\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Assume 'genre' is the target and 'text_features' is the input\n",
    "texts = merged_df['text_features'].astype(str)\n",
    "labels = merged_df['genres']\n",
    "\n",
    "# Encode genres into numerical labels\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Tokenize the texts\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "max_seq_length = 200  # adjust as necessary\n",
    "X = pad_sequences(sequences, maxlen=max_seq_length)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training samples:\", X_train.shape[0])\n",
    "print(\"Test samples:\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building and Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\Columbia\\CU-VIRT-AI-PT-09-2024-U-LOLC-main\\.conda\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d        │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.0633 - loss: 7.4021 - val_accuracy: 0.0741 - val_loss: 5.9534\n",
      "Epoch 2/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.0721 - loss: 5.7189 - val_accuracy: 0.1285 - val_loss: 5.9591\n",
      "Epoch 3/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1029 - loss: 5.4080 - val_accuracy: 0.1417 - val_loss: 6.1061\n",
      "Epoch 4/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1554 - loss: 5.0371 - val_accuracy: 0.2834 - val_loss: 6.0818\n",
      "Epoch 5/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2503 - loss: 4.6476 - val_accuracy: 0.2916 - val_loss: 6.2306\n",
      "Epoch 6/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.2840 - loss: 4.3891 - val_accuracy: 0.3081 - val_loss: 6.2602\n",
      "Epoch 7/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3133 - loss: 4.1474 - val_accuracy: 0.3526 - val_loss: 6.4447\n",
      "Epoch 8/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3406 - loss: 4.0141 - val_accuracy: 0.3690 - val_loss: 6.8068\n",
      "Epoch 9/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3847 - loss: 3.7042 - val_accuracy: 0.3871 - val_loss: 6.9694\n",
      "Epoch 10/10\n",
      "\u001b[1m171/171\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.3772 - loss: 3.6620 - val_accuracy: 0.3855 - val_loss: 7.2229\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=64, input_length=max_seq_length),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the Genre Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3700 - loss: 7.2689\n",
      "Test Accuracy: 0.3746701776981354\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose:\n",
    "We want to convert the text of all 17,000 Amazon reviews into numbers that the computer can work with. We do this using a TF-IDF vectorizer. TF-IDF stands for “Term Frequency-Inverse Document Frequency” and helps us capture which words are most important in each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix for 17k reviews shape: (9296, 5000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "reviews = amazon_df_clean['review/text'].astype(str)\n",
    "\n",
    "# Create a TF-IDF vectorizer; you can adjust max_features as needed.\n",
    "tfidf_vectorizer_reviews = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Fit and transform the review texts into a numerical matrix.\n",
    "tfidf_reviews_matrix = tfidf_vectorizer_reviews.fit_transform(reviews)\n",
    "\n",
    "print(\"TF-IDF matrix for 17k reviews shape:\", tfidf_reviews_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a simple web interface where a user can type in a review. We’ll use Gradio—a tool that makes it easy to create user interfaces for machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Assuming merged_df is our merged dataframe with a 'title' column.\n",
    "book_titles = merged_df['title'].unique().tolist()\n",
    "\n",
    "def user_review_input(book_title, user_review):\n",
    "    # Verify the book exists in our dataset\n",
    "    if book_title not in book_titles:\n",
    "        return \"Book not found in our dataset.\"\n",
    "    return f\"Review for '{book_title}':\\n{user_review}\"\n",
    "\n",
    "# Create a Gradio interface with two inputs: a dropdown for the book title and a textbox for the review.\n",
    "interface = gr.Interface(\n",
    "    fn=user_review_input, \n",
    "    inputs=[\n",
    "        gr.Dropdown(choices=book_titles, label=\"Select Book Title\"),\n",
    "        gr.Textbox(lines=5, placeholder=\"Enter your review here...\", label=\"Your Review\")\n",
    "    ], \n",
    "    outputs=\"text\", \n",
    "    title=\"Book Review Input\",\n",
    "    description=\"Select a book and enter your review.\"\n",
    ")\n",
    "\n",
    "interface.launch()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section takes a review entered by the user, converts it into numbers using the same TF-IDF model we built for the 17k Amazon reviews, and then finds the most similar reviews from our dataset. In simple terms, it’s like comparing the “fingerprint” of the new review to all existing reviews to see which ones match best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similar_reviews(user_review, top_n=5):\n",
    "    # Convert the user's review into its numerical (TF-IDF) representation.\n",
    "    user_review_vector = tfidf_vectorizer_reviews.transform([user_review])\n",
    "    \n",
    "    # Compute similarity scores between the user's review and all 17k reviews.\n",
    "    similarities = cosine_similarity(user_review_vector, tfidf_reviews_matrix)\n",
    "    \n",
    "    # Find the indices of the top_n most similar reviews.\n",
    "    similar_indices = similarities[0].argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Retrieve the matching review texts from the Amazon reviews dataset.\n",
    "    similar_reviews = amazon_df_clean.iloc[similar_indices][['review/text']].reset_index(drop=True)\n",
    "    \n",
    "    # Convert the result to a string for display.\n",
    "    return similar_reviews.to_string(index=False)\n",
    "\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "review_similarity_interface = gr.Interface(\n",
    "    fn=get_similar_reviews,\n",
    "    inputs=gr.Textbox(lines=5, placeholder=\"Enter your review text...\", label=\"Your Review\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Similar Reviews Finder\",\n",
    "    description=\"Enter a review and see the top similar reviews from our dataset.\"\n",
    ")\n",
    "\n",
    "review_similarity_interface.launch()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part uses VADER—a tool that understands the mood of text—to analyze the sentiment of a review. In addition, we use a simple rule: if the review’s rating is above 4, we consider it positive; below 4, negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Mom\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Initialize the VADER sentiment analyzer.\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def analyze_review_sentiment(review_text, rating):\n",
    "    # Use VADER to compute sentiment scores.\n",
    "    sentiment_scores = sia.polarity_scores(review_text)\n",
    "    compound_score = sentiment_scores['compound']\n",
    "    \n",
    "    # Use the numeric rating to decide the review's sentiment.\n",
    "    if rating > 4:\n",
    "        rating_sentiment = \"Positive\"\n",
    "    else:\n",
    "        rating_sentiment = \"Negative\"\n",
    "    \n",
    "    # Format the result for display.\n",
    "    result_str = (\n",
    "        f\"Review: {review_text}\\n\"\n",
    "        f\"Compound Score: {compound_score}\\n\"\n",
    "        f\"Rating Sentiment (by rule): {rating_sentiment}\\n\"\n",
    "        f\"Full VADER Scores: {sentiment_scores}\"\n",
    "    )\n",
    "    return result_str\n",
    "\n",
    "# Create a Gradio interface that takes a review and a rating as inputs.\n",
    "sentiment_interface = gr.Interface(\n",
    "    fn=analyze_review_sentiment,\n",
    "    inputs=[\n",
    "        gr.Textbox(lines=5, placeholder=\"Enter your review text...\", label=\"Your Review\"),\n",
    "        gr.Slider(minimum=1, maximum=5, step=0.1, label=\"Rating\")\n",
    "    ],\n",
    "    outputs=\"text\",\n",
    "    title=\"VADER Sentiment Analysis\",\n",
    "    description=\"Enter a review and its rating to see a sentiment analysis.\"\n",
    ")\n",
    "\n",
    "sentiment_interface.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
